{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow.keras.layers import Flatten  , Dense , MaxPooling2D , Conv2D , BatchNormalization , Dropout\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dir = r\"C:\\Users\\Shreyansh Singh\\Downloads\\archive (36)\\dataset\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5493 images belonging to 11 classes.\n",
      "Found 1369 images belonging to 11 classes.\n"
     ]
    }
   ],
   "source": [
    "datagen = ImageDataGenerator(rescale = 1./255 , validation_split=0.2)\n",
    "train_generator = datagen.flow_from_directory(\n",
    "    dataset_dir , \n",
    "    target_size = (150 , 150),\n",
    "    batch_size = 32,\n",
    "    class_mode = 'categorical',\n",
    "    subset = 'training'\n",
    ")\n",
    "\n",
    "validation_generator = datagen.flow_from_directory(\n",
    "    dataset_dir,\n",
    "    target_size = (150 , 150),\n",
    "    batch_size = 32 , \n",
    "    class_mode = 'categorical',\n",
    "    subset = 'validation'\n",
    ")\n",
    "\n",
    "first_batch_images , first_batch_label = next(train_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 148, 148, 32)      896       \n",
      "                                                                 \n",
      " batch_normalization (Batch  (None, 148, 148, 32)      128       \n",
      " Normalization)                                                  \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2  (None, 74, 74, 32)        0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 72, 72, 64)        18496     \n",
      "                                                                 \n",
      " batch_normalization_1 (Bat  (None, 72, 72, 64)        256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPoolin  (None, 36, 36, 64)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 34, 34, 128)       73856     \n",
      "                                                                 \n",
      " batch_normalization_2 (Bat  (None, 34, 34, 128)       512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPoolin  (None, 17, 17, 128)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 15, 15, 256)       295168    \n",
      "                                                                 \n",
      " batch_normalization_3 (Bat  (None, 15, 15, 256)       1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPoolin  (None, 7, 7, 256)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 12544)             0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 12544)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 512)               6423040   \n",
      "                                                                 \n",
      " batch_normalization_4 (Bat  (None, 512)               2048      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 11)                5643      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6821067 (26.02 MB)\n",
      "Trainable params: 6819083 (26.01 MB)\n",
      "Non-trainable params: 1984 (7.75 KB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32 , (3 , 3) , activation = 'relu' , input_shape = (150 , 150 , 3)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(2 , 2))\n",
    "\n",
    "model.add(Conv2D(64 , (3 , 3) , activation = 'relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(2 , 2))\n",
    "\n",
    "\n",
    "model.add(Conv2D(128 ,(3 , 3) , activation = 'relu' ))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(2 , 2))\n",
    "\n",
    "model.add(Conv2D(256 , (3 , 3) , activation = 'relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(2 , 2))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense( 512 , activation = 'relu' , kernel_regularizer = l2(0.005)))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "num_classes = 11\n",
    "model.add(Dense(num_classes , activation = 'softmax'))\n",
    "\n",
    "model.compile(optimizer = 'adam' , loss = 'categorical_crossentropy' , metrics = ['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "172/172 [==============================] - 267s 2s/step - loss: 5.0632 - accuracy: 0.5826 - val_loss: 7.5194 - val_accuracy: 0.1410\n",
      "Epoch 2/20\n",
      "172/172 [==============================] - 231s 1s/step - loss: 2.3827 - accuracy: 0.6488 - val_loss: 5.8738 - val_accuracy: 0.2009\n",
      "Epoch 3/20\n",
      "172/172 [==============================] - 277s 2s/step - loss: 1.9120 - accuracy: 0.6710 - val_loss: 2.7646 - val_accuracy: 0.4638\n",
      "Epoch 4/20\n",
      "172/172 [==============================] - 229s 1s/step - loss: 1.8157 - accuracy: 0.6900 - val_loss: 2.0897 - val_accuracy: 0.6202\n",
      "Epoch 5/20\n",
      "172/172 [==============================] - 225s 1s/step - loss: 1.7783 - accuracy: 0.7062 - val_loss: 2.5407 - val_accuracy: 0.5113\n",
      "Epoch 6/20\n",
      "172/172 [==============================] - 222s 1s/step - loss: 1.7420 - accuracy: 0.7253 - val_loss: 2.1257 - val_accuracy: 0.5822\n",
      "Epoch 7/20\n",
      "172/172 [==============================] - 220s 1s/step - loss: 1.7615 - accuracy: 0.7346 - val_loss: 2.3507 - val_accuracy: 0.5822\n",
      "Epoch 8/20\n",
      "172/172 [==============================] - 223s 1s/step - loss: 1.7523 - accuracy: 0.7429 - val_loss: 1.8730 - val_accuracy: 0.7275\n",
      "Epoch 9/20\n",
      "172/172 [==============================] - 222s 1s/step - loss: 1.6834 - accuracy: 0.7701 - val_loss: 2.4404 - val_accuracy: 0.5508\n",
      "Epoch 10/20\n",
      "172/172 [==============================] - 222s 1s/step - loss: 1.7320 - accuracy: 0.7746 - val_loss: 2.6362 - val_accuracy: 0.4989\n",
      "Epoch 11/20\n",
      "172/172 [==============================] - 223s 1s/step - loss: 1.7055 - accuracy: 0.7870 - val_loss: 2.5108 - val_accuracy: 0.5939\n",
      "Epoch 12/20\n",
      "172/172 [==============================] - 221s 1s/step - loss: 1.7539 - accuracy: 0.7941 - val_loss: 2.5029 - val_accuracy: 0.5873\n",
      "Epoch 13/20\n",
      "172/172 [==============================] - 222s 1s/step - loss: 1.7588 - accuracy: 0.8021 - val_loss: 2.3926 - val_accuracy: 0.6289\n",
      "Epoch 14/20\n",
      "172/172 [==============================] - 222s 1s/step - loss: 1.6894 - accuracy: 0.8210 - val_loss: 2.9660 - val_accuracy: 0.5091\n",
      "Epoch 15/20\n",
      "172/172 [==============================] - 219s 1s/step - loss: 1.6885 - accuracy: 0.8276 - val_loss: 2.6250 - val_accuracy: 0.5259\n",
      "Epoch 16/20\n",
      "172/172 [==============================] - 223s 1s/step - loss: 1.6832 - accuracy: 0.8414 - val_loss: 2.4855 - val_accuracy: 0.6815\n",
      "Epoch 17/20\n",
      "172/172 [==============================] - 222s 1s/step - loss: 1.6281 - accuracy: 0.8571 - val_loss: 2.7184 - val_accuracy: 0.5800\n",
      "Epoch 18/20\n",
      "172/172 [==============================] - 222s 1s/step - loss: 1.6246 - accuracy: 0.8615 - val_loss: 3.1322 - val_accuracy: 0.4982\n"
     ]
    }
   ],
   "source": [
    "early_stopping = EarlyStopping(\n",
    "    monitor = 'val_accuracy',\n",
    "    patience = 10,\n",
    "    restore_best_weights = True\n",
    ")\n",
    "\n",
    "history = model.fit(train_generator,\n",
    "                    epochs = 20 , \n",
    "                    validation_data = validation_generator,\n",
    "                    callbacks = [early_stopping]\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43/43 [==============================] - 10s 231ms/step - loss: 1.8730 - accuracy: 0.7275\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Shreyansh Singh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\engine\\training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "model.evaluate(validation_generator)\n",
    "model.save('CNN_Image.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"451671ff18f451dbf566b36a66c31c7e\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
